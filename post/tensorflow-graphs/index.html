<!DOCTYPE html>
<html lang=""><head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>Visualising Tensorflow Graphs | Peter Grimshaw&#39;s Site</title>
    <meta name="description" content="Visualising Tensorflow Graphs">
    <meta property="og:site_name" content="Visualising Tensorflow Graphs" />
    <meta property="og:title" content="Peter Grimshaw&#39;s Site" />
    <meta property="og:description" content="Recently I was looking at a Triton Server tutorial which used the tf2onnx utility for converting a tensorflow model to onnx format. Triton is a tool which serves ML models, such as those from the tensorflow framework. Triton has a tensorflow backend, but it doesn&amp;rsquo;t support models from tenorflow v1 like the EAST text detection model used in the tutorial, so it&amp;rsquo;s necessary to convert the model to onnx format to serve it with Triton." />
    <meta property="og:image" content="https://pagrim.github.io/img/peter.jpg" />
    <meta name="keywords"
          content="" />
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css"
        integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI"
          crossorigin="anonymous">

    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js"
        integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t"
        crossorigin="anonymous">
    </script>

    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js"
        integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
        onload="renderMathInElement(document.body);">
    </script>
    
    <meta name="keywords" content="fast, hugo, theme, minimal, gruvbox">
    <link rel="icon" type="image/svg" href='https://pagrim.github.io/img/logo.png' />
    <meta name="author" content='peter_grimshaw'>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.126.2">
    
    <link rel="stylesheet" href="https://pagrim.github.io/sass/main.min.e4732d6df598be088fd42303a85eb416b51788261c37ad61e22a6c43d38facc4.css" type="text/css" media="screen">

    <link rel="stylesheet" href="https://pagrim.github.io/css/style.css">

    

    
    </head>
<body>
      <div class="line" id="scrollIndicator"></div>
      <div class="main"><div class="title">
  <div class="name">
    <h2><a href="https://pagrim.github.io/"
	   style="text-decoration: none; color: inherit;">Peter Grimshaw</a></h2>
  </div>
  <div class="color-scheme">
    <input type="checkbox" class="checkbox" id="chk" />
    <label class="label" for="chk">
						<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="moon" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M283.211 512c78.962 0 151.079-35.925 198.857-94.792 7.068-8.708-.639-21.43-11.562-19.35-124.203 23.654-238.262-71.576-238.262-196.954 0-72.222 38.662-138.635 101.498-174.394 9.686-5.512 7.25-20.197-3.756-22.23A258.156 258.156 0 0 0 283.211 0c-141.309 0-256 114.511-256 256 0 141.309 114.511 256 256 256z"></path></svg>
						<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="sun" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 160c-52.9 0-96 43.1-96
										96s43.1 96 96 96 96-43.1 96-96-43.1-96-96-96zm246.4 80.5l-94.7-47.3 33.5-100.4c4.5-13.6-8.4-26.5-21.9-21.9l-100.4 33.5-47.4-94.8c-6.4-12.8-24.6-12.8-31 0l-47.3 94.7L92.7 70.8c-13.6-4.5-26.5 8.4-21.9 21.9l33.5 100.4-94.7 47.4c-12.8 6.4-12.8 24.6 0 31l94.7 47.3-33.5 100.5c-4.5 13.6 8.4 26.5 21.9 21.9l100.4-33.5 47.3 94.7c6.4 12.8 24.6 12.8 31 0l47.3-94.7 100.4 33.5c13.6 4.5 26.5-8.4 21.9-21.9l-33.5-100.4 94.7-47.3c13-6.5 13-24.7.2-31.1zm-155.9 106c-49.9 49.9-131.1 49.9-181 0-49.9-49.9-49.9-131.1 0-181 49.9-49.9 131.1-49.9 181 0 49.9 49.9 49.9 131.1 0 181z"></path></svg>
      <div class="ball"></div>
    </label>
  </div>
</div>
<script>
  const themeSetter = (theme) => {
      document.body.classList.toggle('dark')
      localStorage.setItem('theme', theme)
      blockSwitcher()
  }

  const blockSwitcher = () => [...document.getElementsByTagName("BLOCKQUOTE")]
	.forEach(b => b.classList.toggle('dark'))

  const styleSwapper = () => {
      document.body.classList.add('back-transition')
      if (localStorage.getItem('theme') === 'dark') themeSetter('light')
      else if (localStorage.getItem('theme') === 'light') themeSetter('dark')
  }

  if (localStorage.getItem('theme') === 'dark'){
      themeSetter('dark')
      document.addEventListener("DOMContentLoaded", blockSwitcher)
  }
 else localStorage.setItem('theme', 'light')

  document.getElementById('chk').addEventListener('change',styleSwapper);

  window.addEventListener("scroll", () => {
      let height = document.documentElement.scrollHeight
          - document.documentElement.clientHeight;
      if(height >= 500){
	  let winScroll = document.body.scrollTop
              || document.documentElement.scrollTop;
	  let scrolled = (winScroll / height) * 100;
	  document.getElementById("scrollIndicator").style.width = scrolled + "%";
      }
  });
</script>

<section class="intro">
  
  <div class="post-header">
    <a class="go-back" href="https://pagrim.github.io/"><svg aria-hidden="true" focusable="false" data-prefix="far" class="back-icon" data-icon="caret-square-left" height="25px" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M272 157.1v197.8c0 10.7-13 16.1-20.5 8.5l-98.3-98.9c-4.7-4.7-4.7-12.2 0-16.9l98.3-98.9c7.5-7.7 20.5-2.3 20.5 8.4zM448 80v352c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V80c0-26.5 21.5-48 48-48h352c26.5 0 48 21.5 48 48zm-48 346V86c0-3.3-2.7-6-6-6H54c-3.3 0-6 2.7-6 6v340c0 3.3 2.7 6 6 6h340c3.3 0 6-2.7 6-6z"></path></svg> </a>
    <h2 class="post-title">Visualising Tensorflow Graphs</h2>
</div>

<p class="post-dets">Published on: November 30, 2024
  | Reading Time: 3 min | Last Modified: November 30, 2024
  <br>
</p>
<span class="tags">
  
  <h5><a class="tag" href='https://pagrim.github.io/tags/tensorflow'>tensorflow</a></h5>
  
  <h5><a class="tag" href='https://pagrim.github.io/tags/model%20graph'>model graph</a></h5>
  
  <h5><a class="tag" href='https://pagrim.github.io/tags/tensorboard'>tensorboard</a></h5>
  
  <h5><a class="tag" href='https://pagrim.github.io/tags/onnx'>onnx</a></h5>
  
  <h5><a class="tag" href='https://pagrim.github.io/tags/triton'>triton</a></h5>
  
</span>

<div class="content">
  <p>Recently I was looking at a Triton Server tutorial which used the <code>tf2onnx</code> utility for converting a tensorflow model to onnx format. Triton is a tool which serves ML models, such as those from the tensorflow framework. Triton has a tensorflow backend, but it doesn&rsquo;t support models from tenorflow v1 like the EAST text detection model used in the tutorial, so it&rsquo;s necessary to convert the model to onnx format to serve it with Triton.</p>
<p>This got me wondering how does this work converting a model from one format to another, and especially, what are these inputs and outputs that you need to specify for the conversion utility? Links to the tutorial and the original paper are at the bottom of the page if you&rsquo;re interested in exploring more.</p>
<h2 id="tf2onnx-example">tf2onnx Example</h2>
<p>This is the command used in the tutorial to convert the tensorflow model to onnx.</p>
<pre tabindex="0"><code>python -m tf2onnx.convert --input frozen_east_text_detection.pb --inputs &#34;input_images:0&#34; --outputs &#34;feature_fusion/Conv_7/Sigmoid:0&#34;,&#34;feature_fusion/concat_3:0&#34; --output detection.onnx
</code></pre><p>Firstly, let&rsquo;s clear up what&rsquo;s otherwise going on in the above command. The <code>tf2onnx.convert</code> utility is being called, and the tenorflow model being converted is the pre-trained model stored in the <code>frozen_east_text_detection.pb</code> file. That&rsquo;s a protobuf file which stores the model graph and weights. The onnx format model is going to be stored at the <code>detection.onnx</code> file location.</p>
<p>I looked into the code and realised that these are nodes in the tensorflow model graph, so, for example <code>input_images:0</code> relates to the first (0 index) node in the graph labelled as <code>input_images</code>. Selecting inputs and outputs allows us to choose which parts of the model graph we would like to be converted to an onnx format.</p>
<p>How can we see the model graph such that we could make such a choice? Tensorflow include a helpful model summary method which can be visualised in Tensorboard. Let&rsquo;s download the tensorflow model <a href="https://www.dropbox.com/s/r2ingd0l3zt8hxs/frozen_east_text_detection.tar.gz">from dropbox here</a> and unpack it.</p>
<pre tabindex="0"><code>tar -xvf frozen_east_text_detection.tar.gz
</code></pre><h2 id="visualising-the-tf-model">Visualising the TF Model</h2>
<p>We can use this python code to use the <code>tf.summary.graph</code> method which writes a summary of the graph using a <code>tf.summary.writer</code>, which in this case writes to the <code>./logs</code> directory. You&rsquo;ll need a python runtime with tensorflow installed for this to work.</p>
<script src="https://gist.github.com/pagrim/b750b4520222ddee35db47978b930c20.js"></script>

<p>Let&rsquo;s create the logs directory, run the code and then visualise with tensorboard.</p>
<pre tabindex="0"><code>mkdir logs
python write_tf_graph.py frozen_east_text_detection.pb
tensorboard --logdir logs
</code></pre><p>This should start tensorboard as a local webserver running on <code>http://localhost:6006/</code>. If you navigate to that address in your web browser you should be able to see the frozen east text detection model visualised as a graph in tensorboard.</p>
<p>In the tensorboard UI, it&rsquo;s easy to navigate the graph and search for the nodes, for example you can search for the node named <code>feature_fusion/Conv_7/Sigmoid</code> and tensorboard will highlight this for you.</p>
<figure><img src="/post/tensorflow-graphs/imgs/tb_search.png"
    alt="Search TF Graph" width="300"><figcaption>
      <p>Search TF Graph in Tensorboard</p>
    </figcaption>
</figure>

<p>You can quickly see that the model is composed of a feature extraction component (in this case resnet50) and a feature fusion component. From looking at the original paper and the tensorflow graph we can see that this node is in the output layer and produces the scores. It&rsquo;s more difficult to see what the <code>feature_fusion/concat_3</code> node is doing, but it seems to produce the geometry outputs according the triton tutorial and we can see from the graph that this is an output node.</p>
<figure><img src="/post/tensorflow-graphs/imgs/east_output_score_component.png"
    alt="Output Component" width="600"><figcaption>
      <p>Output component</p>
    </figcaption>
</figure>

<h2 id="links">Links</h2>
<ul>
<li>Here&rsquo;s the <a href="https://github.com/triton-inference-server/tutorials/tree/main/Conceptual_Guide/Part_1-model_deployment">triton tutorial</a> that sparked my interest</li>
<li>If you&rsquo;re interested in a deep dive into the text detection model, here&rsquo;s the <a href="https://arxiv.org/pdf/1704.03155">EAST text detection original paper</a>.</li>
</ul>

</div>

</section>
<footer id="footer">
    <strong></strong>
    <div class="social">
        &nbsp;
<a href="https://github.com/pagrim" target="_blank" rel="me" title="Github" referrerpolicy="no-referrer">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
	stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
	<path
		d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
	</path>
</svg>
</a>
&nbsp;&nbsp;
<a href="https://www.linkedin.com/in/petergrimshaw/" target="_blank" rel="me" title="Linkedin" referrerpolicy="no-referrer">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
	stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
	<path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
	<rect x="2" y="9" width="4" height="12"></rect>
	<circle cx="4" cy="4" r="2"></circle>
</svg>
</a>
&nbsp;
    </div><strong></strong>
    <p style="color:grey;">© 2024 Peter Grimshaw  <a href="https://creativecommons.org/licenses/by/4.0/">Some rights reserved</a>.</p>
</footer>
</div>
    </body>
</html>
